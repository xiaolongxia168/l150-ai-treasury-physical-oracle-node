#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯†å®¤é€ƒè„± - æ™ºèƒ½å®¢æœAI
åŠŸèƒ½ï¼š7Ã—24è‡ªåŠ¨å›å¤ + å¤šå¹³å°æ¥å…¥ + çŸ¥è¯†åº“ç®¡ç†
"""

import json
import re
from datetime import datetime
from pathlib import Path

class EscapeRoomCustomerServiceAI:
    def __init__(self, workspace_path="/Users/xiaolongxia/.openclaw/workspace/å¯†å®¤é€ƒè„±è¿è¥"):
        self.workspace = Path(workspace_path)
        self.kb_dir = self.workspace / "å®¢æœ" / "çŸ¥è¯†åº“"
        self.chat_dir = self.workspace / "å®¢æœ" / "å¯¹è¯è®°å½•"
        self.log_dir = self.workspace / "æ—¥å¿—"
        
        for dir_path in [self.kb_dir, self.chat_dir, self.log_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        self.knowledge_base = self._load_knowledge_base()
        self.log(f"æ™ºèƒ½å®¢æœAIåˆå§‹åŒ–å®Œæˆ")
    
    def log(self, message):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_file = self.log_dir / f"cs_{datetime.now().strftime('%Y%m%d')}.log"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"[{timestamp}] {message}\n")
        print(f"[CS AI] {message}")
    
    def _load_knowledge_base(self):
        """åŠ è½½çŸ¥è¯†åº“"""
        kb_file = self.kb_dir / "knowledge_base.json"
        
        if kb_file.exists():
            with open(kb_file, "r", encoding="utf-8") as f:
                return json.load(f)
        
        # åˆ›å»ºé»˜è®¤çŸ¥è¯†åº“
        default_kb = {
            "version": "1.0",
            "last_update": datetime.now().isoformat(),
            "categories": {
                "pricing": {
                    "keywords": ["ä»·æ ¼", "å¤šå°‘é’±", "è´¹ç”¨", "å›¢è´­", "ä¼˜æƒ ", "ä¾¿å®œ", "è´µ"],
                    "responses": [
                        "æ‚¨å¥½ï¼æˆ‘ä»¬ç›®å‰æœ‰å¤šä¸ªä¸»é¢˜å¯é€‰ï¼Œä»·æ ¼ä»{price_range}ä¸ç­‰ã€‚ç°åœ¨é¢„è®¢è¿˜æœ‰{discount}ä¼˜æƒ å“¦ï¼",
                        "æˆ‘ä»¬çš„å›¢è´­å¥—é¤éå¸¸åˆ’ç®—ï¼å¹³æ—¥ç¥¨{weekday_price}å…ƒï¼Œå‘¨æœ«{weekend_price}å…ƒã€‚ç‚¹å‡»ä¸‹æ–¹é“¾æ¥ç«‹å³é¢„è®¢ ğŸ‘‡"
                    ],
                    "data": {
                        "price_range": "88-168å…ƒ",
                        "discount": "8æŠ˜",
                        "weekday_price": "88",
                        "weekend_price": "128"
                    }
                },
                "themes": {
                    "keywords": ["ä¸»é¢˜", "æœ‰ä»€ä¹ˆ", "æ¨è", "ææ€–", "æ‚¬ç–‘", "è§£è°œ", "å‰§æƒ…"],
                    "responses": [
                        "æˆ‘ä»¬æœ‰5å¤§çƒ­é—¨ä¸»é¢˜ï¼š\nğŸ­ {theme_1}\nğŸ­ {theme_2}\nğŸ­ {theme_3}\nğŸ­ {theme_4}\nğŸ­ {theme_5}\n\næ¯ä¸ªä¸»é¢˜æ—¶é•¿60-90åˆ†é’Ÿï¼Œæ‚¨åå¥½å“ªç§é£æ ¼ï¼Ÿ",
                        "å¼ºçƒˆæ¨èæˆ‘ä»¬çš„æ‹›ç‰Œä¸»é¢˜ã€Š{top_theme}ã€‹ï¼{theme_desc} é€‚åˆ{player_count}äººä½“éªŒ~"
                    ],
                    "data": {
                        "theme_1": "åˆå¤œå‡¶é“ƒï¼ˆææ€–ï¼‰",
                        "theme_2": "ç¦å°”æ‘©æ–¯ï¼ˆæ¨ç†ï¼‰",
                        "theme_3": "å¤å¢“ä¸½å½±ï¼ˆå†’é™©ï¼‰",
                        "theme_4": "æ—¶é—´è£‚ç¼ï¼ˆç§‘å¹»ï¼‰",
                        "theme_5": "æ°‘å›½å¾€äº‹ï¼ˆå‰§æƒ…ï¼‰",
                        "top_theme": "åˆå¤œå‡¶é“ƒ",
                        "theme_desc": "æ²‰æµ¸å¼ææ€–ä½“éªŒï¼ŒçœŸäººNPCäº’åŠ¨",
                        "player_count": "4-8"
                    }
                },
                "booking": {
                    "keywords": ["é¢„è®¢", "é¢„çº¦", "è®¢åœº", "æ—¶é—´", "åœºæ¬¡", "ç©ºä½"],
                    "responses": [
                        "é¢„è®¢å¾ˆç®€å•ï¼è¯·å‘Šè¯‰æˆ‘ï¼š\n1ï¸âƒ£ é€‰æ‹©ä¸»é¢˜\n2ï¸âƒ£ é€‰æ‹©æ—¥æœŸå’Œæ—¶é—´\n3ï¸âƒ£ ç¡®è®¤äººæ•°\n\næˆ‘æ¥ä¸ºæ‚¨æŸ¥è¯¢ç©ºä½~",
                        "ä»Šå¤©çš„åœºæ¬¡è¿˜æœ‰ï¼š{today_slots}\næ˜å¤©ï¼š{tomorrow_slots}\næ‚¨æƒ³è®¢å“ªä¸ªæ—¶æ®µï¼Ÿ"
                    ],
                    "data": {
                        "today_slots": "14:00, 16:00, 19:00, 21:00",
                        "tomorrow_slots": "10:00, 14:00, 16:00, 19:00, 21:00"
                    }
                },
                "location": {
                    "keywords": ["åœ°å€", "åœ¨å“ª", "ä½ç½®", "æ€ä¹ˆå»", "åœè½¦", "åœ°é“", "å…¬äº¤"],
                    "responses": [
                        "ğŸ“ æˆ‘ä»¬çš„åœ°å€æ˜¯ï¼š{address}\n\nğŸš‡ åœ°é“ï¼š{metro}\nğŸšŒ å…¬äº¤ï¼š{bus}\nğŸ…¿ï¸ åœè½¦ï¼š{parking}",
                        "æˆ‘ä»¬åœ¨{location_name}ï¼Œ{landmark}æ—è¾¹ï¼Œå¾ˆæ˜¾çœ¼çš„ä½ç½®~"
                    ],
                    "data": {
                        "address": "å¾…å¡«å†™",
                        "metro": "å¾…å¡«å†™",
                        "bus": "å¾…å¡«å†™",
                        "parking": "å¾…å¡«å†™",
                        "location_name": "å¾…å¡«å†™",
                        "landmark": "å¾…å¡«å†™"
                    }
                },
                "refund": {
                    "keywords": ["é€€æ¬¾", "å–æ¶ˆ", "æ”¹æœŸ", "é€€é’±", "èƒ½é€€å—"],
                    "responses": [
                        "å…³äºé€€æ¬¾æ”¿ç­–ï¼š\nâœ… æå‰24å°æ—¶å–æ¶ˆï¼šå…¨é¢é€€æ¬¾\nâœ… æå‰12å°æ—¶ï¼šé€€æ¬¾80%\nâŒ å½“å¤©å–æ¶ˆï¼šä¸å¯é€€æ¬¾\n\nå¦‚éœ€æ”¹æœŸï¼Œè¯·æå‰è”ç³»~",
                        "ç‰¹æ®Šæƒ…å†µï¼ˆå¦‚ç–«æƒ…ã€æç«¯å¤©æ°”ï¼‰å¯ä»¥ç”³è¯·ç‰¹æ®Šå¤„ç†ï¼Œæˆ‘ä»¬ä¼šå°½åŠ›ååŠ©ï¼"
                    ],
                    "data": {}
                },
                "requirements": {
                    "keywords": ["å¹´é¾„", "é™åˆ¶", "å‡ ä¸ªäºº", "äººæ•°", "å°å­©", "å„¿ç«¥", "å­•å¦‡"],
                    "responses": [
                        "å‚ä¸è¦æ±‚ï¼š\nğŸ‘¥ äººæ•°ï¼š{min_players}-{max_players}äºº/åœº\nğŸ‚ å¹´é¾„ï¼š{age_limit}\nâš ï¸ æ³¨æ„äº‹é¡¹ï¼š{notes}",
                        "ææ€–ä¸»é¢˜å»ºè®®16å²ä»¥ä¸Šï¼Œè§£è°œä¸»é¢˜10å²ä»¥ä¸Šéƒ½å¯ä»¥ç©~"
                    ],
                    "data": {
                        "min_players": "2",
                        "max_players": "8",
                        "age_limit": "10å²ä»¥ä¸Šï¼ˆææ€–ä¸»é¢˜16+ï¼‰",
                        "notes": "å¿ƒè„ç—…ã€é«˜è¡€å‹æ‚£è€…åŠå­•å¦‡ä¸å»ºè®®å‚ä¸"
                    }
                },
                "hours": {
                    "keywords": ["è¥ä¸šæ—¶é—´", "å‡ ç‚¹", "å…³é—¨", "å¼€é—¨", "è¥ä¸šåˆ°"],
                    "responses": [
                        "â° è¥ä¸šæ—¶é—´ï¼š\nå‘¨ä¸€è‡³å‘¨äº”ï¼š{weekday_hours}\nå‘¨æœ«åŠèŠ‚å‡æ—¥ï¼š{weekend_hours}\n\næœ€æ™šå…¥åœºæ—¶é—´ï¼š{last_entry}",
                        "å»ºè®®æå‰30åˆ†é’Ÿåˆ°åº—ï¼Œå¯ä»¥æŒ‘é€‰è§’è‰²å’Œç†Ÿæ‚‰è§„åˆ™~"
                    ],
                    "data": {
                        "weekday_hours": "13:00-22:00",
                        "weekend_hours": "10:00-23:00",
                        "last_entry": "21:00"
                    }
                }
            },
            "default_responses": [
                "æ‚¨å¥½ï¼æ¬¢è¿å’¨è¯¢æˆ‘ä»¬çš„å¯†å®¤é€ƒè„±~ è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ",
                "æ”¶åˆ°æ‚¨çš„é—®é¢˜ï¼è®©æˆ‘ä¸ºæ‚¨è§£ç­”...",
                "è¿™ä¸ªå’¨è¯¢æœ‰ç‚¹å¤æ‚ï¼Œæˆ‘ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·ç¨ç­‰~"
            ],
            "escort_keywords": ["æŠ•è¯‰", "å·®è¯„", "ç»ç†", "è€æ¿", "äººå·¥", "å®¢æœ", "é€€é’±", "ä¸¾æŠ¥"]
        }
        
        with open(kb_file, "w", encoding="utf-8") as f:
            json.dump(default_kb, f, ensure_ascii=False, indent=2)
        
        self.log(f"åˆ›å»ºé»˜è®¤çŸ¥è¯†åº“: {kb_file}")
        return default_kb
    
    def detect_intent(self, message):
        """æ„å›¾è¯†åˆ«"""
        message = message.lower()
        
        for category, data in self.knowledge_base["categories"].items():
            for keyword in data["keywords"]:
                if keyword in message:
                    return category
        
        return "default"
    
    def detect_emotion(self, message):
        """æƒ…ç»ªæ£€æµ‹"""
        negative_words = ["å·®", "åƒåœ¾", "å‘", "éª—", "æ°”", "å¤±æœ›", "ä¸çˆ½", "å·®è¯„", "æŠ•è¯‰"]
        positive_words = ["å¥½", "æ£’", "èµ", "å–œæ¬¢", "æ»¡æ„", "ä¸é”™", "æ¨è", "å¥½ç©"]
        urgent_words = ["æ€¥", "é©¬ä¸Š", "ç«‹åˆ»", "ç°åœ¨", "å¿«"]
        
        emotion_score = 0
        
        for word in negative_words:
            if word in message:
                emotion_score -= 1
        
        for word in positive_words:
            if word in message:
                emotion_score += 1
        
        urgency = any(word in message for word in urgent_words)
        
        if emotion_score < 0:
            return "negative", urgency
        elif emotion_score > 0:
            return "positive", urgency
        else:
            return "neutral", urgency
    
    def generate_response(self, message, platform="unknown"):
        """ç”Ÿæˆå›å¤"""
        timestamp = datetime.now().isoformat()
        
        # æ£€æµ‹æ„å›¾
        intent = self.detect_intent(message)
        emotion, urgency = self.detect_emotion(message)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬äººå·¥
        for keyword in self.knowledge_base.get("escort_keywords", []):
            if keyword in message:
                response = "[SYSTEM] è§¦å‘äººå·¥è½¬æ¥ - å…³é”®è¯åŒ¹é…"
                self._log_conversation(timestamp, platform, message, response, intent, emotion, True)
                return response
        
        # è´Ÿé¢æƒ…ç»ªä¸”ç´§æ€¥
        if emotion == "negative" and urgency:
            response = self.knowledge_base["default_responses"][2]
            self._log_conversation(timestamp, platform, message, response, intent, emotion, True)
            return response
        
        # æ ¹æ®æ„å›¾ç”Ÿæˆå›å¤
        if intent in self.knowledge_base["categories"]:
            category_data = self.knowledge_base["categories"][intent]
            import random
            template = random.choice(category_data["responses"])
            response = template.format(**category_data.get("data", {}))
        else:
            response = self.knowledge_base["default_responses"][0]
        
        # æƒ…ç»ªå®‰æŠš
        if emotion == "negative":
            response = "éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸å¥½çš„ä½“éªŒï¼" + response
        
        self._log_conversation(timestamp, platform, message, response, intent, emotion, False)
        return response
    
    def _log_conversation(self, timestamp, platform, user_msg, ai_response, intent, emotion, escalated):
        """è®°å½•å¯¹è¯"""
        log_entry = {
            "timestamp": timestamp,
            "platform": platform,
            "user_message": user_msg,
            "ai_response": ai_response,
            "intent": intent,
            "emotion": emotion,
            "escalated": escalated
        }
        
        log_file = self.chat_dir / f"conversations_{datetime.now().strftime('%Y%m%d')}.jsonl"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    
    def simulate_conversation(self, test_messages=None):
        """æ¨¡æ‹Ÿå¯¹è¯æµ‹è¯•"""
        if not test_messages:
            test_messages = [
                ("douyin", "å¤šå°‘é’±ä¸€ä¸ªäººï¼Ÿ"),
                ("meituan", "æœ‰ä»€ä¹ˆä¸»é¢˜æ¨èï¼Ÿ"),
                ("xiaohongshu", "åœ°å€åœ¨å“ªé‡Œï¼Ÿ"),
                ("wechat", "å¯ä»¥é€€æ¬¾å—ï¼Ÿ"),
                ("douyin", "å¤ªå·®äº†ï¼æˆ‘è¦æŠ•è¯‰ï¼")
            ]
        
        self.log("=" * 50)
        self.log("å¼€å§‹æ¨¡æ‹Ÿå¯¹è¯æµ‹è¯•")
        self.log("=" * 50)
        
        for platform, msg in test_messages:
            response = self.generate_response(msg, platform)
            print(f"\n[{platform}] ç”¨æˆ·: {msg}")
            print(f"[AI] å›å¤: {response}")
        
        self.log("=" * 50)
        self.log("æ¨¡æ‹Ÿæµ‹è¯•å®Œæˆ")
        self.log("=" * 50)
    
    def update_knowledge_base(self, category, data):
        """æ›´æ–°çŸ¥è¯†åº“"""
        if category in self.knowledge_base["categories"]:
            self.knowledge_base["categories"][category]["data"].update(data)
            self.knowledge_base["last_update"] = datetime.now().isoformat()
            
            kb_file = self.kb_dir / "knowledge_base.json"
            with open(kb_file, "w", encoding="utf-8") as f:
                json.dump(self.knowledge_base, f, ensure_ascii=False, indent=2)
            
            self.log(f"æ›´æ–°çŸ¥è¯†åº“[{category}]: {data}")
            return True
        return False
    
    def get_stats(self):
        """è·å–å®¢æœç»Ÿè®¡"""
        today = datetime.now().strftime('%Y%m%d')
        log_file = self.chat_dir / f"conversations_{today}.jsonl"
        
        stats = {
            "total_conversations": 0,
            "by_platform": {},
            "by_intent": {},
            "escalation_rate": 0,
            "emotion_distribution": {"positive": 0, "neutral": 0, "negative": 0}
        }
        
        if log_file.exists():
            with open(log_file, "r", encoding="utf-8") as f:
                for line in f:
                    entry = json.loads(line.strip())
                    stats["total_conversations"] += 1
                    stats["by_platform"][entry["platform"]] = stats["by_platform"].get(entry["platform"], 0) + 1
                    stats["by_intent"][entry["intent"]] = stats["by_intent"].get(entry["intent"], 0) + 1
                    stats["emotion_distribution"][entry["emotion"]] += 1
                    if entry["escalated"]:
                        stats["escalation_rate"] += 1
            
            if stats["total_conversations"] > 0:
                stats["escalation_rate"] = stats["escalation_rate"] / stats["total_conversations"]
        
        return stats


if __name__ == "__main__":
    cs_ai = EscapeRoomCustomerServiceAI()
    
    print("\n" + "=" * 60)
    print("ğŸ¤– æ™ºèƒ½å®¢æœAIæµ‹è¯•å¯åŠ¨")
    print("=" * 60)
    
    # è¿è¡Œæ¨¡æ‹Ÿå¯¹è¯
    cs_ai.simulate_conversation()
    
    # è¾“å‡ºç»Ÿè®¡
    stats = cs_ai.get_stats()
    print(f"\nğŸ“Š ä»Šæ—¥å¯¹è¯ç»Ÿè®¡:")
    print(f"   æ€»å¯¹è¯æ•°: {stats['total_conversations']}")
    print(f"   è½¬äººå·¥ç‡: {stats['escalation_rate']:.1%}")
    print(f"   æƒ…ç»ªåˆ†å¸ƒ: {stats['emotion_distribution']}")
    
    print("\nâœ… æ™ºèƒ½å®¢æœAIæµ‹è¯•å®Œæˆ!")
