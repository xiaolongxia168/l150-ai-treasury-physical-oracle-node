#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘è½¬å½•ä¸AIçŸ¥è¯†åº“æŠ•å–‚ç³»ç»Ÿ
åŠŸèƒ½ï¼šæ‰¹é‡æå–è§†é¢‘éŸ³é¢‘ â†’ Whisper APIè½¬å½• â†’ ç»“æ„åŒ–å­˜å‚¨ â†’ AIè¿è¥çŸ¥è¯†åº“
"""

import os
import sys
import json
import time
import subprocess
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests

# ============ é…ç½® ============
CONFIG = {
    "video_dir": "/Users/xiaolongxia/Downloads/ç¾å›¢è¿è¥/å·…å³°æµé‡Â·å®ä½“å›¢è´­æ“ç›˜æ‰‹ã€æ­£å¼ç‰ˆã€‘",
    "audio_output_dir": "/Users/xiaolongxia/.openclaw/workspace/analysis/meituan-course/audio-extracted",
    "transcript_output_dir": "/Users/xiaolongxia/.openclaw/workspace/analysis/meituan-course/transcripts-api",
    "knowledge_base_dir": "/Users/xiaolongxia/.openclaw/workspace/å¯†å®¤é€ƒè„±è¿è¥/çŸ¥è¯†åº“/è¯¾ç¨‹è½¬å½•",
    "progress_file": "/Users/xiaolongxia/.openclaw/workspace/analysis/meituan-course/.transcribe_progress.json",
    "log_file": "/Users/xiaolongxia/.openclaw/workspace/analysis/meituan-course/transcribe.log",
    
    # APIé…ç½®
    "openai_api_key": os.getenv("OPENAI_API_KEY", ""),
    "whisper_model": "whisper-1",
    "whisper_language": "zh",
    
    # å¹¶å‘é…ç½®
    "max_workers": 2,  # åŒæ—¶å¤„ç†2ä¸ªè§†é¢‘
    "api_timeout": 300,  # APIè°ƒç”¨è¶…æ—¶5åˆ†é’Ÿ
}

# ============ æ—¥å¿—ç³»ç»Ÿ ============
class Logger:
    def __init__(self, log_file):
        self.log_file = log_file
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
    
    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_line = f"[{timestamp}] [{level}] {message}"
        print(log_line)
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_line + "\n")
    
    def info(self, msg): self.log(msg, "INFO")
    def success(self, msg): self.log(msg, "SUCCESS")
    def warning(self, msg): self.log(msg, "WARNING")
    def error(self, msg): self.log(msg, "ERROR")

logger = Logger(CONFIG["log_file"])

# ============ è¿›åº¦ç®¡ç† ============
class ProgressManager:
    def __init__(self, progress_file):
        self.progress_file = progress_file
        self.completed = self._load()
    
    def _load(self):
        if os.path.exists(self.progress_file):
            with open(self.progress_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return {"completed_videos": [], "completed_transcripts": []}
    
    def save(self):
        with open(self.progress_file, "w", encoding="utf-8") as f:
            json.dump(self.completed, f, ensure_ascii=False, indent=2)
    
    def is_video_extracted(self, video_path):
        return video_path in self.completed.get("completed_videos", [])
    
    def is_transcribed(self, video_path):
        return video_path in self.completed.get("completed_transcripts", [])
    
    def mark_video_extracted(self, video_path):
        if video_path not in self.completed["completed_videos"]:
            self.completed["completed_videos"].append(video_path)
            self.save()
    
    def mark_transcribed(self, video_path):
        if video_path not in self.completed["completed_transcripts"]:
            self.completed["completed_transcripts"].append(video_path)
            self.save()

progress = ProgressManager(CONFIG["progress_file"])

# ============ è§†é¢‘å¤„ç†ç±» ============
class VideoProcessor:
    def __init__(self):
        self.video_dir = Path(CONFIG["video_dir"])
        self.audio_dir = Path(CONFIG["audio_output_dir"])
        self.transcript_dir = Path(CONFIG["transcript_output_dir"])
        self.kb_dir = Path(CONFIG["knowledge_base_dir"])
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.audio_dir.mkdir(parents=True, exist_ok=True)
        self.transcript_dir.mkdir(parents=True, exist_ok=True)
        self.kb_dir.mkdir(parents=True, exist_ok=True)
    
    def scan_videos(self):
        """æ‰«ææ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
        videos = []
        for ext in ["*.mp4", "*.MP4", "*.mov", "*.MOV"]:
            videos.extend(self.video_dir.rglob(ext))
        return sorted(videos)
    
    def extract_audio(self, video_path):
        """æå–éŸ³é¢‘ï¼ˆä½¿ç”¨FFmpegï¼‰"""
        video_path = Path(video_path)
        base_name = video_path.stem
        audio_path = self.audio_dir / f"{base_name}.mp3"
        
        # æ£€æŸ¥æ˜¯å¦å·²æå–
        if progress.is_video_extracted(str(video_path)) and audio_path.exists():
            logger.info(f"â­ï¸  éŸ³é¢‘å·²æå–ï¼Œè·³è¿‡: {base_name}")
            return str(audio_path)
        
        logger.info(f"ğŸµ æå–éŸ³é¢‘: {base_name}")
        
        cmd = [
            "ffmpeg",
            "-i", str(video_path),
            "-vn",  # ä¸å¤„ç†è§†é¢‘
            "-acodec", "libmp3lame",
            "-ar", "16000",  # 16kHzé‡‡æ ·ç‡ï¼ˆWhisperæ¨èï¼‰
            "-ac", "1",  # å•å£°é“
            "-b:a", "32k",  # 32kbpsç ç‡
            "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            str(audio_path)
        ]
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode == 0:
                video_size = video_path.stat().st_size / (1024 * 1024)
                audio_size = audio_path.stat().st_size / (1024 * 1024)
                logger.success(f"  âœ… æå–å®Œæˆ: {video_size:.1f}MB â†’ {audio_size:.1f}MB ({audio_size/video_size*100:.1f}%)")
                progress.mark_video_extracted(str(video_path))
                return str(audio_path)
            else:
                logger.error(f"  âŒ FFmpegé”™è¯¯: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            logger.error(f"  â±ï¸  æå–è¶…æ—¶: {base_name}")
            return None
        except Exception as e:
            logger.error(f"  âŒ æå–å¤±è´¥: {base_name} - {str(e)}")
            return None
    
    def transcribe_with_whisper(self, audio_path, video_path):
        """ä½¿ç”¨æœ¬åœ°Whisperè½¬å½•"""
        audio_path = Path(audio_path)
        base_name = audio_path.stem
        transcript_path = self.transcript_dir / f"{base_name}.txt"
        
        # æ£€æŸ¥æ˜¯å¦å·²è½¬å½•
        if progress.is_transcribed(str(video_path)) and transcript_path.exists():
            logger.info(f"â­ï¸  å·²è½¬å½•ï¼Œè·³è¿‡: {base_name}")
            return str(transcript_path)
        
        logger.info(f"ğŸ¯ æœ¬åœ°Whisperè½¬å½•: {base_name}")
        
        try:
            import whisper
            
            # åŠ è½½æ¨¡å‹ (smallæ¨¡å‹å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®åº¦)
            logger.info(f"  ğŸ”„ åŠ è½½Whisperæ¨¡å‹...")
            model = whisper.load_model("small")
            
            # è½¬å½•
            logger.info(f"  ğŸ“ å¼€å§‹è½¬å½•...")
            result = model.transcribe(
                str(audio_path),
                language="zh",
                verbose=False,
                initial_prompt="è¿™æ˜¯ä¸€æ®µå…³äºç¾å›¢è¿è¥å’Œå®ä½“åº—å›¢è´­çš„æ•™ç¨‹è§†é¢‘ã€‚"
            )
            
            transcript_text = result["text"]
            transcript_path.write_text(transcript_text, encoding="utf-8")
            
            char_count = len(transcript_text)
            logger.success(f"  âœ… è½¬å½•å®Œæˆ: {base_name} ({char_count} å­—ç¬¦)")
            progress.mark_transcribed(str(video_path))
            return str(transcript_path)
            
        except ImportError:
            logger.error(f"  âŒ æœªå®‰è£…Whisper: pip3 install openai-whisper")
            return None
        except Exception as e:
            logger.error(f"  âŒ è½¬å½•å¤±è´¥: {base_name} - {str(e)}")
            return None
    
    def generate_summary(self, transcript_path, video_path):
        """ç”Ÿæˆå†…å®¹æ‘˜è¦å’Œç»“æ„åŒ–æ•°æ®"""
        transcript_path = Path(transcript_path)
        base_name = transcript_path.stem
        
        # è¯»å–è½¬å½•æ–‡æœ¬
        transcript_text = transcript_path.read_text(encoding="utf-8")
        
        # æå–å…ƒæ•°æ®
        metadata = {
            "video_name": base_name,
            "video_path": str(video_path),
            "transcript_path": str(transcript_path),
            "processed_at": datetime.now().isoformat(),
            "char_count": len(transcript_text),
            "word_count": len(transcript_text.split()),
            "category": self._extract_category(base_name),
        }
        
        # ç”Ÿæˆæ‘˜è¦ï¼ˆç®€å•æå–å‰500å­—ä½œä¸ºæ‘˜è¦ï¼‰
        summary = transcript_text[:500] + "..." if len(transcript_text) > 500 else transcript_text
        metadata["summary"] = summary
        
        # æå–å…³é”®ä¸»é¢˜ï¼ˆç®€å•çš„å…³é”®è¯åŒ¹é…ï¼‰
        keywords = self._extract_keywords(transcript_text)
        metadata["keywords"] = keywords
        
        return metadata
    
    def _extract_category(self, filename):
        """ä»æ–‡ä»¶åæå–åˆ†ç±»"""
        categories = {
            "è¯„ä»·": "è¯„ä»·ä¸æ˜Ÿçº§è¯„åˆ†",
            "æ¨å¹¿é€š": "æ¨å¹¿é€š",
            "åå°æ•°æ®": "åå°æ•°æ®åˆ†æ",
            "æµé‡": "æµé‡è¿è¥",
            "è½¬åŒ–": "è½¬åŒ–ä¼˜åŒ–",
        }
        for key, value in categories.items():
            if key in filename:
                return value
        return "å…¶ä»–"
    
    def _extract_keywords(self, text):
        """æå–å…³é”®è¯"""
        keywords = []
        keyword_patterns = [
            "ç¾å›¢", "å¤§ä¼—ç‚¹è¯„", "æ˜Ÿçº§", "è¯„ä»·", "æ¨å¹¿é€š", "æµé‡",
            "è½¬åŒ–", "ROI", "CPA", "CPC", "è‡ªç„¶æµé‡", "ä»˜è´¹æ¨å¹¿",
            "æ¦œå•", "å¥½è¯„", "å·®è¯„", "å›å¤", "è¿è¥", "å›¢è´­"
        ]
        for keyword in keyword_patterns:
            if keyword in text:
                keywords.append(keyword)
        return list(set(keywords))[:10]  # æœ€å¤š10ä¸ªå…³é”®è¯
    
    def save_to_knowledge_base(self, metadata, transcript_text):
        """ä¿å­˜åˆ°AIè¿è¥çŸ¥è¯†åº“"""
        base_name = metadata["video_name"]
        
        # ä¿å­˜ç»“æ„åŒ–JSON
        json_path = self.kb_dir / f"{base_name}.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜Markdownæ ¼å¼ï¼ˆä¾¿äºé˜…è¯»å’ŒRAGï¼‰
        md_path = self.kb_dir / f"{base_name}.md"
        md_content = f"""# {base_name}

## å…ƒæ•°æ®
- **åˆ†ç±»**: {metadata['category']}
- **å¤„ç†æ—¶é—´**: {metadata['processed_at']}
- **å­—ç¬¦æ•°**: {metadata['char_count']}
- **å…³é”®è¯**: {', '.join(metadata['keywords'])}

## æ‘˜è¦
{metadata['summary']}

## å®Œæ•´å†…å®¹
{transcript_text}

---
*è‡ªåŠ¨ç”Ÿæˆçš„è¿è¥çŸ¥è¯†åº“æ–‡æ¡£*
"""
        md_path.write_text(md_content, encoding="utf-8")
        
        logger.success(f"  ğŸ’¾ å·²ä¿å­˜åˆ°çŸ¥è¯†åº“: {base_name}")
        return str(md_path)
    
    def process_single_video(self, video_path):
        """å¤„ç†å•ä¸ªè§†é¢‘çš„å®Œæ•´æµç¨‹"""
        video_path = Path(video_path)
        base_name = video_path.stem
        
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ“¹ å¼€å§‹å¤„ç†: {base_name}")
        logger.info(f"{'='*50}")
        
        # æ­¥éª¤1: æå–éŸ³é¢‘
        audio_path = self.extract_audio(video_path)
        if not audio_path:
            logger.error(f"âŒ éŸ³é¢‘æå–å¤±è´¥ï¼Œè·³è¿‡: {base_name}")
            return False
        
        # æ­¥éª¤2: Whisperè½¬å½•
        transcript_path = self.transcribe_with_whisper(audio_path, video_path)
        if not transcript_path:
            logger.error(f"âŒ è½¬å½•å¤±è´¥ï¼Œè·³è¿‡: {base_name}")
            return False
        
        # æ­¥éª¤3: ç”Ÿæˆæ‘˜è¦å’Œç»“æ„åŒ–æ•°æ®
        transcript_text = Path(transcript_path).read_text(encoding="utf-8")
        metadata = self.generate_summary(transcript_path, video_path)
        
        # æ­¥éª¤4: ä¿å­˜åˆ°çŸ¥è¯†åº“
        self.save_to_knowledge_base(metadata, transcript_text)
        
        logger.success(f"âœ… å®Œæˆå¤„ç†: {base_name}")
        return True
    
    def run(self, max_workers=None):
        """è¿è¡Œæ‰¹é‡å¤„ç†"""
        if max_workers is None:
            max_workers = CONFIG["max_workers"]
        
        logger.info("ğŸš€ å¯åŠ¨è§†é¢‘è½¬å½•ä¸çŸ¥è¯†åº“æŠ•å–‚ç³»ç»Ÿ")
        logger.info(f"ğŸ“ è§†é¢‘ç›®å½•: {CONFIG['video_dir']}")
        
        # æ‰«æè§†é¢‘
        videos = self.scan_videos()
        if not videos:
            logger.error("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return
        
        logger.info(f"ğŸ“¹ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        # ç»Ÿè®¡å¾…å¤„ç†æ•°é‡
        pending = [v for v in videos if not progress.is_transcribed(str(v))]
        logger.info(f"â³ å¾…å¤„ç†: {len(pending)} ä¸ªï¼Œå·²è·³è¿‡: {len(videos) - len(pending)} ä¸ª")
        
        # æ‰¹é‡å¤„ç†
        success_count = 0
        fail_count = 0
        
        for i, video_path in enumerate(videos, 1):
            logger.info(f"\n[{i}/{len(videos)}] å¤„ç†è¿›åº¦")
            
            if self.process_single_video(video_path):
                success_count += 1
            else:
                fail_count += 1
            
            # æ¯å¤„ç†å®Œä¸€ä¸ªï¼ŒçŸ­æš‚ä¼‘æ¯é¿å…APIé™æµ
            time.sleep(1)
        
        # ç»Ÿè®¡æŠ¥å‘Š
        logger.info(f"\n{'='*50}")
        logger.info("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
        logger.info(f"{'='*50}")
        logger.info(f"æ€»è®¡: {len(videos)} ä¸ªè§†é¢‘")
        logger.info(f"æˆåŠŸ: {success_count} ä¸ª")
        logger.info(f"å¤±è´¥: {fail_count} ä¸ª")
        logger.info(f"\nğŸ“‚ è¾“å‡ºç›®å½•:")
        logger.info(f"   éŸ³é¢‘: {CONFIG['audio_output_dir']}")
        logger.info(f"   æ–‡æœ¬: {CONFIG['transcript_output_dir']}")
        logger.info(f"   çŸ¥è¯†åº“: {CONFIG['knowledge_base_dir']}")
        logger.info(f"   æ—¥å¿—: {CONFIG['log_file']}")

# ============ ä¸»å‡½æ•° ============
def main():
    processor = VideoProcessor()
    processor.run()

def show_stats():
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    processor = VideoProcessor()
    videos = processor.scan_videos()
    
    print("\n" + "="*50)
    print("ğŸ“Š è½¬å½•ç»Ÿè®¡")
    print("="*50)
    print(f"æ€»è§†é¢‘æ•°: {len(videos)}")
    print(f"å·²å®Œæˆ: {len(progress.completed.get('completed_transcripts', []))}")
    print(f"å‰©ä½™: {len(videos) - len(progress.completed.get('completed_transcripts', []))}")
    print("\nè§†é¢‘åˆ—è¡¨:")
    for i, v in enumerate(videos, 1):
        status = "âœ…" if progress.is_transcribed(str(v)) else "â³"
        print(f"  {status} {i}. {v.name}")

def reset_progress():
    """é‡ç½®è¿›åº¦"""
    if os.path.exists(CONFIG["progress_file"]):
        os.remove(CONFIG["progress_file"])
    print("âœ… è¿›åº¦å·²é‡ç½®")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] in ["stats", "-s", "--stats"]:
            show_stats()
        elif sys.argv[1] in ["reset", "-r", "--reset"]:
            reset_progress()
        elif sys.argv[1] in ["help", "-h", "--help"]:
            print("""è§†é¢‘è½¬å½•ä¸AIçŸ¥è¯†åº“æŠ•å–‚ç³»ç»Ÿ

ç”¨æ³•: python3 transcribe_and_feed.py [é€‰é¡¹]

é€‰é¡¹:
  (æ— )       å¼€å§‹æ‰¹é‡å¤„ç†
  stats      æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
  reset      é‡ç½®å¤„ç†è¿›åº¦
  help       æ˜¾ç¤ºå¸®åŠ©

ç¯å¢ƒå˜é‡:
  OPENAI_API_KEY    OpenAI APIå¯†é’¥ (å¿…éœ€)
""")
        else:
            print(f"æœªçŸ¥é€‰é¡¹: {sys.argv[1]}")
    else:
        main()
